# Cell 1 - Import the libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier 
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.metrics import accuracy_score

# Cell 2 - Loads the csv file and display the array shape
Raw_Data = pd.read_csv('Example data.csv', index_col=0, header=[0,1]) # Note file name for your own data
Raw_Data.shape 

# Cell 3 - View raw spectra
Raw_Data.plot(kind='line',legend=False, figsize=(12,4))

# Cell 4 - Add a colour scheme for identification on classes and view spectra again
colormap = {
    '1': '#ff0000',  # Red - Class 1
    '2': '#0000ff',  # Blue - Class 2
    '3': '#00ff00',  # Green - Class 3
    '4': '#FF00FF',  # Purple - Class 4
    '5': '#0f0f0f',  # Black - Unknown   
}
colorlist = [colormap[c] for c in Raw_Data.columns.get_level_values('Group')]
Raw_Data.plot(kind='line', legend=False, figsize=(12,4), color=colorlist)

# Cell 5 - Pre-processing Binning - Note only as required. If not required remove this step.
# Separate Labels
y = pd.DataFrame.to_numpy(Raw_Data.columns.get_level_values('Group'))
# Binning 
bins = np.linspace(AAA, BBB, num=ZZZ) # Select range AAA - BBB and number of bins ZZZ
groups = Raw_Data.groupby(np.digitize(Raw_Data.index,bins))
# Get the mean of each bin
Binned_Data=groups.sum()
# Check new array shape
Binned_Data.shape

# Cell 6 - View binned data
Binned_Data.plot(kind='line',legend=False, figsize=(12,4), color=colorlist)

# Cell 7 - Pre-processing Data - Scaling - Note there are several methods available including normalising or standardising.
# Transposed
Transposed_Data = pd.DataFrame.to_numpy(Binned_Data.T)
# Scaling data 
Normalised_Data = preprocessing.normalize(Transposed_Data)
# Export and viewing preprocessed data
ND = pd.DataFrame(Normalised_Data)
ND.to_csv('z-Normalised_Binned_Data.csv', header=True) # Name of exported pre-processed data will be z-Normalised_Data.csv
(ND.T).plot(kind='line',legend=False, figsize=(12,4), color=colorlist)

# Cell 8 - Perform and exporting PCA data
pca = PCA(n_components=4) # Select number of Principle Component
pca_data = pca.fit_transform(Normalised_Data[AAA:BBB]) # Select statistical modelling data range AAA to BBB
per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)
PCA_Data= pd.DataFrame(data = pca_data, columns = ['PC' + str(x) for x in range(1, len(per_var)+1)])
PCA_Data.to_csv('z-PCA_Data.csv', header=True) # Name of exported PCA data will be z-PCA_Data.csv

# Cell 9 - Graphing the scree plot
labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]
plt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)
plt.ylabel('% of Explained Variance')
plt.xlabel('Principle Component')
plt.title('Scree Plot')
plt.show()

# Cell 10 - % variance explained by individual PC
explained_variance = pca.explained_variance_ratio_
print(explained_variance)

# Cell 11 - Total % explained variance by the No. of PC selected
np.sum(explained_variance)

# Cell 12 - Plot PCA
PCA_Data.plot(x=0, y=1, kind='scatter', s=200, alpha=0.6, c=colorlist[AAA:BBB], figsize=(8,8)) # Note that PCA range must match
plt.ylabel('Principle Component 2')
plt.xlabel('Principle Component 1')
plt.title('Principal Component Analysis')

# Cell 13 - Loading scores for PC 1 - Current selection for top 10 contributing bands or features
Loading_Scores = pd.Series(pca.components_[0])
Sorted_Loading_Scores = Loading_Scores.abs().sort_values(ascending=False)
Top_10_Bins = Sorted_Loading_Scores[0:10].index.values
print (Loading_Scores[Top_10_Bins])

# Cell 14 - Viewing and exporting loading scores for PC 1
Loading_Scores.plot(kind='line', figsize=(12,4))
Loading_Scores.to_csv('z - Loading Scores PC 1.csv', header=True)

# Cell 15 - Loading scores for PC 2 - Current selection for top 10 contributing bands or features
Loading_Scores2 = pd.Series(pca.components_[1])
Sorted_Loading_Scores2 = Loading_Scores2.abs().sort_values(ascending=False)
Top_10_Bins2 = Sorted_Loading_Scores2[0:10].index.values
print (Loading_Scores2[Top_10_Bins2])

# Cell 16 - Viewing and exporting loading scores for PC 2
Loading_Scores2.plot(kind='line', figsize=(12,4))
Loading_Scores2.to_csv('z - Loading Scores PC 2.csv', header=True)

# Cell 17 - Function for summing an area of the spectra/bin to calculate area under the curve from point XXX to YYY
Point_1 = ND.T[XXX:YYY].sum()
Point_1.to_csv('w - Binned_Data.csv', header=True)

# Cell 18 - Perform PCA on validation set
test_pca_data = pca.fit_transform(Normalised_Data)
test_pca_data2= pd.DataFrame(test_pca_data)
print('Validation set shape:', test_pca_data2[BBB:CCC].shape) # Select validation set data range BBB to CCC
per_var2 = np.round(pca.explained_variance_ratio_* 100, decimals=1)
PCA_Data2 = pd.DataFrame(data = test_pca_data2, columns = ['PC' + str(x) for x in range(1, len(per_var2)+1)])
test_pca_data2[BBB:CCC].plot(x=0, y=1, kind='scatter', s=200, alpha=0.6, c=colorlist[BBB:CCC], figsize=(8,8))
plt.ylabel('Principle Component 2')
plt.xlabel('Principle Component 1')
plt.title('Validation set PCA')

# Cell 19 - Exporting validation set PCA data
test_pca_data2.to_csv('z-PCA_Test_Data.csv', header=True)

# Cell 20 - Establish Train and Test sets
X_train, X_test, y_train, y_test = train_test_split(PCA_Data, y[AAA:BBB], test_size=0.2, random_state=4)
print('Training data shape:', X_train.shape)
print('Testing data shape:', X_test.shape)

# Cell 21 - K Fold Cross Validation
model=DecisionTreeClassifier()
kfold_validation=KFold(7)
results=cross_val_score(model, PCA_Data, y[AAA:BBB], cv=kfold_validation)
print(results)
print(np.mean(results))

# Cell 22 - Stratified K-fold Cross Validation
skfold=StratifiedKFold(n_splits=7)
model=DecisionTreeClassifier()
scores=cross_val_score(model, PCA_Data, y[AAA:BBB],cv=skfold)
print(scores)
print(np.mean(scores))

# Cell 23 - Leave One Out Cross Validation (LOOCV)
from sklearn.model_selection import LeaveOneOut
model=DecisionTreeClassifier()
leave_validation=LeaveOneOut()
results=cross_val_score(model, PCA_Data, y[AAA:BBB], cv=leave_validation)
print(np.mean(results))

#Cell 24 - Create KNN Classifier
knn = KNeighborsClassifier(n_neighbors=3)
#Train the model using the training sets
knn.fit(X_train, y_train)
#Predict the response for test dataset
y_pred = knn.predict(X_test)

# Cell 25 - Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

# Running prediction on validation set
prediction = knn.predict(test_pca_data2[BBB:CCC])
Result = pd.DataFrame(prediction, y[BBB:CCC])
Result
